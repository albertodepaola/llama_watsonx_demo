{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b852d7e5-51ce-4600-bc70-fc9b26dbd215",
   "metadata": {},
   "source": [
    "# <center>Desenvolvendo Aplicações de IA Seguras com watsonx e Meta Llama 3</center>\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Bem-vindo ao workshop \"Desenvolvendo Aplicações de IA Seguras com watsonx e Meta Llama 3\"! Este evento faz parte do TDC Floripa 2024, um dos maiores eventos de tecnologia do Brasil. Prepare-se para uma sessão prática e enriquecedora onde você aprenderá a criar aplicações de IA seguras e bem-governadas utilizando as plataformas IBM watsonx e a família de modelos Llama 3 da Meta.\n",
    "\n",
    "### Descrição\n",
    "\n",
    "Neste workshop prático, você terá a oportunidade única de dominar a arte de criar aplicações seguras e bem-governadas usando as plataformas IBM watsonx e a família de modelos Llama 3 da Meta. Ideal para desenvolvedores que desejam estar à frente da inovação em IA, este workshop oferece uma visão completa nas melhores práticas de segurança e governança em LLMs. Não perca a chance de melhorar suas habilidades, aprender diretamente com experts das duas empresas e conectar-se com outros profissionais apaixonados por tecnologia. Inscreva-se agora e seja pioneiro em desenvolver soluções de IA que não só inovam, mas também protegem e respeitam as normas de governança e segurança digital!\n",
    "\n",
    "### Instrutores\n",
    "\n",
    "- **André Lopes (IBM)**\n",
    "- **Beto de Paola (Meta)**\n",
    "\n",
    "### Duração\n",
    "\n",
    "- **1 hora e 30 minutos**\n",
    "\n",
    "### Tópicos Abordados\n",
    "\n",
    "- Introdução à plataforma IBM watsonx\n",
    "- Modelos da família Llama 3 da Meta\n",
    "- Conceitos de Prompt Engineering\n",
    "- Governança e segurança das aplicações de LLMs\n",
    "\n",
    "---\n",
    "\n",
    "## Agenda do Workshop\n",
    "\n",
    "1. **Introdução às Plataformas**\n",
    "   - Visão geral do IBM watsonx\n",
    "   - Introdução aos modelos Llama 3 da Meta\n",
    "     \n",
    "<br>\n",
    "\n",
    "2. **Prompt Engineering**\n",
    "   - Técnicas e melhores práticas\n",
    "   - Exemplos práticos\n",
    "\n",
    "<br>\n",
    "\n",
    "3. **Governança e Segurança**\n",
    "   - Princípios de governança em IA\n",
    "   - Implementação de medidas de segurança\n",
    "\n",
    "<br>\n",
    "\n",
    "4. **Hands-on Session**\n",
    "   - Aplicação prática dos conceitos aprendidos\n",
    "   - Desenvolvimento de uma aplicação segura com watsonx e Llama 3\n",
    "\n",
    "<br>\n",
    "\n",
    "5. **Q&A**\n",
    "   - Perguntas e Respostas com os Instrutores\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "## Pré-requisitos\n",
    "\n",
    "Para tirar o máximo proveito deste workshop, é recomendável ter:\n",
    "\n",
    "- Conhecimento básico em desenvolvimento de IA com Python.\n",
    "- Experiência prévia com plataformas de Machine Learning.\n",
    "- Curiosidade e vontade de aprender sobre Segurança e Governança em IA.\n",
    "\n",
    "---\n",
    "\n",
    "Vamos começar? Siga os passos abaixo para configurar seu ambiente de desenvolvimento e esteja pronto para explorar o fascinante mundo da IA segura e governada com watsonx e Llama 3!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f74e8-8404-4833-939a-76d04f849cbe",
   "metadata": {},
   "source": [
    "# Instalando as dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85d7a861-540b-469d-8692-87dc3eb451a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install ibm-watson-machine-learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd11bb5-77c4-4d84-b810-50b940736e6e",
   "metadata": {},
   "source": [
    "# Preparando o Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a65c9f1c-9e03-4df4-a719-887cd96e775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a841aba-c1a3-47fc-94a1-72a57be5657a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config watsonx.ai environment\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"API_KEY\", None)\n",
    "ibm_cloud_url = 'https://us-south.ml.cloud.ibm.com/'\n",
    "project_id = '071e4dd8-0da4-4972-be85-bead673469bf'\n",
    "if api_key is None or ibm_cloud_url is None or project_id is None:\n",
    "    print('Ensure you copied the .env file that you created earlier into the same directory as this notebook')\n",
    "else:\n",
    "    creds = {\n",
    "        'url': ibm_cloud_url,\n",
    "        'apikey': api_key \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60feda9-d7bb-4e5f-957f-ffef3845b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_to_watsonxai(prompt,\n",
    "                    model_name='meta-llama/llama-3-70b-instruct', # Meta Llama 3\n",
    "                    decoding_method='greedy',\n",
    "                    max_new_tokens=400,\n",
    "                    min_new_tokens=1,\n",
    "                    stop_sequences=['}\\n'],\n",
    "                    temperature=1.0,\n",
    "                    repetition_penalty=1.0\n",
    "                    ):\n",
    "    \"\"\"\n",
    "   Helper function for sending prompts and params to watsonx.ai\n",
    "    \n",
    "    Args:  \n",
    "        prompts:list list of text prompts\n",
    "        decoding:str Watsonx.ai parameter \"sample\" or \"greedy\"\n",
    "        max_new_tok:int Watsonx.ai parameter for max new tokens/response returned\n",
    "        stop_sequences:list[str] sequence pre-defined to stop generating text\n",
    "        temperature:float Watsonx.ai parameter for temperature (range 0>2)\n",
    "        repetition_penalty:float Watsonx.ai parameter for repetition penalty (range 1.0 to 2.0)\n",
    "\n",
    "    Returns: None\n",
    "        prints response\n",
    "    \"\"\"\n",
    "\n",
    "    # Instantiate parameters for text generation\n",
    "    model_params = {\n",
    "        GenParams.DECODING_METHOD: decoding_method,\n",
    "        GenParams.MIN_NEW_TOKENS: min_new_tokens,\n",
    "        GenParams.MAX_NEW_TOKENS: max_new_tokens,\n",
    "        GenParams.RANDOM_SEED: 42,\n",
    "        GenParams.STOP_SEQUENCES: stop_sequences,\n",
    "        GenParams.TEMPERATURE: temperature,\n",
    "        GenParams.REPETITION_PENALTY: repetition_penalty,\n",
    "    }\n",
    "\n",
    "    model = Model(\n",
    "        model_id=model_name,\n",
    "        params=model_params,\n",
    "        credentials=creds,\n",
    "        project_id=project_id)\n",
    "\n",
    "    return model.generate_text(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccae9065-a3de-448f-9eb0-df3d135d782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Edible flowers are flowers that are safe for human consumption and can be used as a garnish or added to dishes for flavor, texture, and visual appeal. They can be used fresh or dried and can be found in various forms, such as petals, leaves, or entire flowers.\n",
      "\n",
      "What are some examples of edible flowers?\n",
      "------------------------------------------\n",
      "\n",
      "Here are some examples of edible flowers:\n",
      "\n",
      "1. **Roses**: Rose petals can be used in salads, desserts, and as a garnish. They have a sweet, floral flavor.\n",
      "2. **Lavender**: Lavender flowers can be used in baked goods, teas, and as a garnish. They have a calming, floral flavor.\n",
      "3. **Nasturtium**: Nasturtium flowers have a peppery, spicy flavor and can be used in salads, as a garnish, or as a topping for soups.\n",
      "4. **Marigold**: Marigold petals have a strong, pungent flavor and can be used in soups, stews, and as a garnish.\n",
      "5. **Chive blossoms**: Chive blossoms have a mild onion flavor and can be used as a garnish or added to salads.\n",
      "6. **Pansy**: Pansy flowers have a sweet, grassy flavor and can be used in salads, desserts, and as a garnish.\n",
      "7. **Hibiscus**: Hibiscus flowers can be used to make tea, sorbet, and jelly. They have a cranberry-like flavor.\n",
      "8. **Violets**: Violet flowers have a sweet, floral flavor and can be used in salads, desserts, and as a garnish.\n",
      "9. **Dandelion**: Dandelion flowers can be used in salads, as a garnish, or as a topping for soups. They have a bitter, earthy flavor.\n",
      "10. **Borage**: Borage flowers have a sweet, slightly nutty flavor and can be used\n"
     ]
    }
   ],
   "source": [
    "# Testing the helper function and API\n",
    "test = send_to_watsonxai(prompt='What are edible flowers?')\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554074b7-a7a6-47f9-b7ee-7eb1bb9001bf",
   "metadata": {},
   "source": [
    "# Carregando a lista de Feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b373683-06b9-4820-8dd7-055c9b370c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the JSON file with feedbacks\n",
    "file_path = './data/feedbacks_list.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b263daa3-3402-4b57-8163-46a46ec9913d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feedback 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The IBM TechXchange event definitely did not meet expectations. The schedule, although it promised significant innovations, was delivered in a confusing and disorganized manner, seriously testing my patience. Additionally, the promised interactivity fell far short, with few real opportunities for audience engagement, which was a great disappointment. However, the topics covered were highly relevant to the industry, and the invited speakers were highly qualified, providing valuable insights. Despite this, the poor execution made it difficult to fully appreciate the few positive aspects of the event.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Feedback 1:')\n",
    "data['feedbacks'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b56ef35-0add-43cd-acdd-f96d91c01082",
   "metadata": {},
   "source": [
    "# Construindo o Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a02735b6-b069-45ba-945c-987fd0ab9eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(feedback):\n",
    "    prompt = f\"\"\"Classify the customer feedbacks below and return a rating indicating \\\n",
    "whether the feedback was positive or negative, the positive points of the feedback, \\\n",
    "the negative points of the feedback, the improvement points of the feedback, the sentiment \\\n",
    "of the feedback, if there is a risk of the customer becoming a detractor of the event, and a \\\n",
    "summary of the feedback in a single sentence covering all the main points.\n",
    "\n",
    "Input:\n",
    "The IBM talk on innovations in cognitive technology left much to be desired in terms of \\\n",
    "organization and depth. The speaker, despite clearly knowing the subject, was hampered by \\\n",
    "an overloaded agenda, resulting in rushed explanations and little time for questions. Additionally, \\\n",
    "the choice of venue did not favor networking, being too small for the number of participants. \\\n",
    "On the other hand, the practical examples shared were quite illustrative, and the distributed \\\n",
    "material was well-prepared, offering a good overview of the possible applications of the technology \\\n",
    "in different industries. It's a shame that the execution did not live up to the promised content.\n",
    "\n",
    "Output:\n",
    "{{\n",
    "\"rating\": \"negative\",\n",
    "\"positive_points\": [\"Illustrative practical examples\", \"Well-prepared material\"],\n",
    "\"negative_points\": [\"Poor organization\", \"Overloaded agenda\", \"Little time for questions\", \"Small venue for networking\"],\n",
    "\"improvement_points\": [\"Improve organization\", \"Adjust agenda\", \"Choose larger venues\"],\n",
    "\"sentiment\": \"Frustration\",\n",
    "\"risk_detractor\": true,\n",
    "\"summary\": \"The IBM talk on cognitive technology was marred by poor organization and insufficient \\\n",
    "depth, despite the speaker's knowledge and quality material.\"\n",
    "}}\n",
    "\n",
    "Input:\n",
    "{feedback}\n",
    "\n",
    "Output:\"\"\"\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd61e9f0-c1c2-4b28-b474-09ee9c8d3af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the customer feedbacks below and return a rating indicating whether the feedback was positive or negative, the positive points of the feedback, the negative points of the feedback, the improvement points of the feedback, the sentiment of the feedback, if there is a risk of the customer becoming a detractor of the event, and a summary of the feedback in a single sentence covering all the main points.\n",
      "\n",
      "Input:\n",
      "The IBM talk on innovations in cognitive technology left much to be desired in terms of organization and depth. The speaker, despite clearly knowing the subject, was hampered by an overloaded agenda, resulting in rushed explanations and little time for questions. Additionally, the choice of venue did not favor networking, being too small for the number of participants. On the other hand, the practical examples shared were quite illustrative, and the distributed material was well-prepared, offering a good overview of the possible applications of the technology in different industries. It's a shame that the execution did not live up to the promised content.\n",
      "\n",
      "Output:\n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Illustrative practical examples\", \"Well-prepared material\"],\n",
      "\"negative_points\": [\"Poor organization\", \"Overloaded agenda\", \"Little time for questions\", \"Small venue for networking\"],\n",
      "\"improvement_points\": [\"Improve organization\", \"Adjust agenda\", \"Choose larger venues\"],\n",
      "\"sentiment\": \"Frustration\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM talk on cognitive technology was marred by poor organization and insufficient depth, despite the speaker's knowledge and quality material.\"\n",
      "}\n",
      "\n",
      "Input:\n",
      "The IBM TechXchange event definitely did not meet expectations. The schedule, although it promised significant innovations, was delivered in a confusing and disorganized manner, seriously testing my patience. Additionally, the promised interactivity fell far short, with few real opportunities for audience engagement, which was a great disappointment. However, the topics covered were highly relevant to the industry, and the invited speakers were highly qualified, providing valuable insights. Despite this, the poor execution made it difficult to fully appreciate the few positive aspects of the event.\n",
      "\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "prompt_1 = build_prompt(data['feedbacks'][1])\n",
    "print(prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fee7af-1554-45d9-bd40-388e4181993f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Relevant topics\", \"Qualified speakers\", \"Valuable insights\"],\n",
      "\"negative_points\": [\"Disorganized schedule\", \"Lack of interactivity\", \"Poor execution\"],\n",
      "\"improvement_points\": [\"Improve schedule organization\", \"Increase interactivity\", \"Better execution\"],\n",
      "\"sentiment\": \"Disappointment\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM TechXchange event failed to meet expectations due to poor organization and lack of interactivity, despite covering relevant topics and featuring qualified speakers.\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = send_to_watsonxai(prompt_1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9234c200-8bff-492a-b93d-c94e692fd2b6",
   "metadata": {},
   "source": [
    "# Validando a Resposta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e9b92dc-751f-4ba8-9949-5e400b061b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_json(json_string):\n",
    "    \"\"\"\n",
    "    Validate a JSON string.\n",
    "\n",
    "    Parameters:\n",
    "    json_string (str): The JSON string to validate.\n",
    "\n",
    "    Returns:\n",
    "    bool: True if the JSON string is valid, False otherwise.\n",
    "    str: Error message if the JSON string is invalid, None if it is valid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        json.loads(json_string)\n",
    "        return True, None\n",
    "    except json.JSONDecodeError as e:\n",
    "        return False, str(e)\n",
    "    except Exception as e:\n",
    "        return False, str(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72e9c3aa-3852-4fbd-b0fc-db36ce325306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Relevant topics\", \"Qualified speakers\", \"Valuable insights\"],\n",
      "\"negative_points\": [\"Disorganized schedule\", \"Lack of interactivity\", \"Poor execution\"],\n",
      "\"improvement_points\": [\"Improve schedule organization\", \"Increase interactivity\", \"Better execution\"],\n",
      "\"sentiment\": \"Disappointment\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM TechXchange event failed to meet expectations due to poor organization and lack of interactivity, despite covering relevant topics and featuring qualified speakers.\"\n",
      "}\n",
      "\n",
      "\n",
      "The JSON response is valid.\n"
     ]
    }
   ],
   "source": [
    "# Print the JSON response\n",
    "print(response)\n",
    "print()\n",
    "\n",
    "# Validate the JSON response\n",
    "is_valid, error_message = validate_json(response)\n",
    "\n",
    "if is_valid:\n",
    "    print('The JSON response is valid.')\n",
    "else:\n",
    "    print(f'The JSON response is invalid: {error_message}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc121bd0-6d01-487e-a8c0-44d6d2562b34",
   "metadata": {},
   "source": [
    "# Analisando toda a base de Feedbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f37bc44-9ce7-428d-b28c-bcf9a52458e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the list of prompts\n",
    "prompts = []\n",
    "\n",
    "for feedback in data['feedbacks']:\n",
    "    prompts.append(build_prompt(feedback))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fefe5211-6c88-4828-b4af-e51e41bddaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3023a83-8574-4edd-acd0-5d1e5cc36dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classify the customer feedbacks below and return a rating indicating whether the feedback was positive or negative, the positive points of the feedback, the negative points of the feedback, the improvement points of the feedback, the sentiment of the feedback, if there is a risk of the customer becoming a detractor of the event, and a summary of the feedback in a single sentence covering all the main points.\n",
      "\n",
      "Input:\n",
      "The IBM talk on innovations in cognitive technology left much to be desired in terms of organization and depth. The speaker, despite clearly knowing the subject, was hampered by an overloaded agenda, resulting in rushed explanations and little time for questions. Additionally, the choice of venue did not favor networking, being too small for the number of participants. On the other hand, the practical examples shared were quite illustrative, and the distributed material was well-prepared, offering a good overview of the possible applications of the technology in different industries. It's a shame that the execution did not live up to the promised content.\n",
      "\n",
      "Output:\n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Illustrative practical examples\", \"Well-prepared material\"],\n",
      "\"negative_points\": [\"Poor organization\", \"Overloaded agenda\", \"Little time for questions\", \"Small venue for networking\"],\n",
      "\"improvement_points\": [\"Improve organization\", \"Adjust agenda\", \"Choose larger venues\"],\n",
      "\"sentiment\": \"Frustration\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM talk on cognitive technology was marred by poor organization and insufficient depth, despite the speaker's knowledge and quality material.\"\n",
      "}\n",
      "\n",
      "Input:\n",
      "The IBM Think event, despite its promises, left much to be desired, which is concerning for those seeking serious advancements in the field of technology. Firstly, the extremely dense agenda made it impossible to delve deeply into any topic, which was quite frustrating. Additionally, the failure to promote an inclusive and welcoming environment, especially for new participants, was notably negligent. The quality of the streaming also left much to be desired, with frequent interruptions that compromised the experience of remote attendees. On a positive note, I must mention the excellent curation of topics, which was aligned with the latest industry trends, and the presence of some renowned experts, who managed to convey their valuable knowledge as best as they could.\n",
      "\n",
      "Output:\n"
     ]
    }
   ],
   "source": [
    "print(prompts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f42f9d50-ea65-4a0e-bf1c-6cc67383ab80",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = send_to_watsonxai(prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "280494a5-e149-4485-8802-55989d777092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c801533c-68ce-46ed-a1ca-ad115bd49adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IBM lecture on innovations in cognitive technology left much to be desired in terms of organization and depth. The speaker, although clearly knowledgeable about the subject, was hindered by an overcrowded schedule, resulting in rushed explanations and little time for questions. Additionally, the choice of venue did not favor networking, being too small for the number of participants. On the other hand, the practical examples shared were quite illustrative, and the distributed materials were well-prepared, offering a good overview of the potential applications of the technology in different industries. It's a pity that the execution did not live up to the promised content.\n",
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Illustrative practical examples\", \"Well-prepared materials\"],\n",
      "\"negative_points\": [\"Poor organization\", \"Overcrowded schedule\", \"Little time for questions\", \"Small venue for networking\"],\n",
      "\"improvement_points\": [\"Improve organization\", \"Adjust schedule\", \"Choose larger venues\"],\n",
      "\"sentiment\": \"Disappointment\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM lecture on cognitive technology was marred by poor organization and insufficient depth, despite the speaker's knowledge and quality materials.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The IBM TechXchange event definitely did not meet expectations. The schedule, although it promised significant innovations, was delivered in a confusing and disorganized manner, seriously testing my patience. Additionally, the promised interactivity fell far short, with few real opportunities for audience engagement, which was a great disappointment. However, the topics covered were highly relevant to the industry, and the invited speakers were highly qualified, providing valuable insights. Despite this, the poor execution made it difficult to fully appreciate the few positive aspects of the event.\n",
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Relevant topics\", \"Qualified speakers\"],\n",
      "\"negative_points\": [\"Disorganized schedule\", \"Lack of interactivity\", \"Poor execution\"],\n",
      "\"improvement_points\": [\"Improve schedule organization\", \"Increase audience engagement opportunities\"],\n",
      "\"sentiment\": \"Disappointment\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM TechXchange event failed to meet expectations due to poor organization and lack of interactivity, despite covering relevant topics and featuring qualified speakers.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The IBM Think event, despite its promises, left much to be desired, which is concerning for those seeking serious advancements in the field of technology. Firstly, the extremely dense agenda made it impossible to delve deeply into any topic, which was quite frustrating. Additionally, the failure to promote an inclusive and welcoming environment, especially for new participants, was notably negligent. The quality of the streaming also left much to be desired, with frequent interruptions that compromised the experience of remote attendees. On a positive note, I must mention the excellent curation of topics, which was aligned with the latest industry trends, and the presence of some renowned experts, who managed to convey their valuable knowledge as best as they could.\n",
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Excellent curation of topics\", \"Renowned experts\"],\n",
      "\"negative_points\": [\"Dense agenda\", \"Lack of inclusive environment\", \"Poor streaming quality\"],\n",
      "\"improvement_points\": [\"Improve agenda\", \"Promote inclusive environment\", \"Enhance streaming quality\"],\n",
      "\"sentiment\": \"Disappointment\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM Think event failed to deliver on its promises, with a dense agenda, poor streaming quality, and lack of inclusivity, despite excellent topic curation and renowned experts.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "While the AI Forum had an impressive lineup of speakers and some insightful sessions, the event was poorly organized. The registration process was chaotic, with long lines and inadequate staff to handle the volume of attendees. There were significant delays in the schedule, causing attendees to miss parts of sessions or have to choose between overlapping ones. Additionally, the venue was overcrowded, making it difficult to navigate between sessions and effectively network. The signage was also confusing, leading to frustration. Despite these issues, the content quality was high, and the keynote speeches were very informative and forward-thinking. The speakers were top-notch and provided valuable insights into the latest AI trends and developments.\n",
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Impressive lineup of speakers\", \"Insightful sessions\", \"High-quality content\", \"Informative keynote speeches\", \"Top-notch speakers\"],\n",
      "\"negative_points\": [\"Poor organization\", \"Chaotic registration process\", \"Long lines\", \"Inadequate staff\", \"Delays in schedule\", \"Overcrowded venue\", \"Confusing signage\"],\n",
      "\"improvement_points\": [\"Improve organization\", \"Streamline registration process\", \"Increase staff\", \"Adjust schedule\", \"Choose larger venues\", \"Improve signage\"],\n",
      "\"sentiment\": \"Frustration\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The AI Forum had impressive speakers and insightful sessions, but was marred by poor organization, chaotic registration, and overcrowding, leading to frustration.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "Think had a lot of potential with its diverse range of topics and knowledgeable presenters, covering everything from AI to cloud computing. However, the event was marred by technical issues during the virtual sessions. The streaming quality was inconsistent, with frequent buffering and sudden disconnects, which was frustrating for remote attendees trying to follow along. The platform used for the event was not user-friendly, making it difficult to access session materials and interact with presenters. On a positive note, the Q&A sessions, when they worked, were very interactive and engaging, allowing attendees to ask detailed questions and receive expert responses. The content itself was well-curated and relevant, showcasing IBM's leadership in the tech industry.\n",
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Diverse range of topics\", \"Knowledgeable presenters\", \"Interactive Q&A sessions\", \"Well-curated content\"],\n",
      "\"negative_points\": [\"Technical issues during virtual sessions\", \"Inconsistent streaming quality\", \"User-unfriendly platform\"],\n",
      "\"improvement_points\": [\"Improve technical infrastructure\", \"Choose a more user-friendly platform\"],\n",
      "\"sentiment\": \"Frustration\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"Think had great content and knowledgeable presenters, but was marred by technical issues and a poor platform, causing frustration for remote attendees.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "TechXchange provided some excellent technical workshops and hands-on labs, offering practical skills and knowledge that were highly appreciated. Unfortunately, the scheduling was poorly planned, with many interesting sessions overlapping, forcing attendees to make difficult choices and miss out on valuable content. The event also lacked adequate breaks between sessions, leading to attendee fatigue. Additionally, the catering was subpar, with limited options for those with dietary restrictions, and the food quality left much to be desired. Despite these organizational flaws, the expert-led sessions were very educational, and the presenters were highly knowledgeable and engaging, making the technical content accessible and actionable.\n",
      " \n",
      "{\n",
      "\"rating\": \"neutral\",\n",
      "\"positive_points\": [\"Excellent technical workshops\", \"Hands-on labs\", \"Expert-led sessions\", \"Knowledgeable and engaging presenters\"],\n",
      "\"negative_points\": [\"Poor scheduling\", \"Inadequate breaks\", \"Subpar catering\", \"Limited options for dietary restrictions\"],\n",
      "\"improvement_points\": [\"Improve scheduling\", \"Increase breaks\", \"Enhance catering options\"],\n",
      "\"sentiment\": \"Mixed\",\n",
      "\"risk_detractor\": false,\n",
      "\"summary\": \"TechXchange offered valuable technical content, but was marred by poor scheduling, inadequate breaks, and subpar catering.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The RTE event featured some very relevant and cutting-edge topics, drawing in a crowd of professionals eager to learn. However, the overall experience was disappointing. The event app was difficult to navigate, with important information about the schedule and speakers hard to find. Many attendees reported issues with the app crashing or not updating in real-time. The networking opportunities were also limited, with few structured activities to facilitate meaningful connections. That said, the speakers were very knowledgeable, and the presentations were well-prepared and insightful. The content was top-notch, providing deep dives into emerging technologies and trends.\n",
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"Relevant and cutting-edge topics\", \"Knowledgeable speakers\", \"Well-prepared presentations\", \"Top-notch content\"],\n",
      "\"negative_points\": [\"Difficult to navigate event app\", \"App crashing or not updating\", \"Limited networking opportunities\"],\n",
      "\"improvement_points\": [\"Improve event app\", \"Increase structured networking activities\"],\n",
      "\"sentiment\": \"Disappointment\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The RTE event had excellent content, but was let down by a poor event app and limited networking opportunities.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "TechNights had a great atmosphere and a lot of potential for learning and networking, with a vibrant and enthusiastic community. However, the sound quality during the presentations was poor, making it hard to follow along and diminishing the overall experience. Many attendees struggled to hear the speakers, especially in larger sessions. Additionally, the event was too short to cover all the interesting topics in depth, leaving attendees feeling like they missed out on valuable information. Despite these issues, the content was relevant, and the speakers were very engaging, providing insights and sparking interesting discussions among attendees. The networking sessions, although limited, were productive and allowed for some good connections.\n",
      " \n",
      "{\n",
      "\"rating\": \"neutral\",\n",
      "\"positive_points\": [\"Great atmosphere\", \"Vibrant community\", \"Engaging speakers\", \"Productive networking sessions\"],\n",
      "\"negative_points\": [\"Poor sound quality\", \"Too short to cover all topics\", \"Limited networking sessions\"],\n",
      "\"improvement_points\": [\"Improve sound quality\", \"Increase event duration\", \"Expand networking opportunities\"],\n",
      "\"sentiment\": \"Mixed\",\n",
      "\"risk_detractor\": false,\n",
      "\"summary\": \"TechNights had a great atmosphere and engaging speakers, but was marred by poor sound quality and limited time to cover all topics, leaving attendees feeling like they missed out.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The Women in Data Science event was inspiring and featured some amazing speakers who shared their personal journeys and professional insights. However, the event was not well-publicized, leading to a lower turnout than expected, which was disappointing given the importance of the topic. Additionally, there were very few opportunities for audience interaction and networking, which is crucial for such events. The sessions were largely one-sided, with limited chances for attendees to ask questions or engage in discussions. Nonetheless, the talks were very motivating and provided valuable insights into the challenges and opportunities for women in the field of data science. The speakers were passionate and knowledgeable, making the content compelling and inspiring.\n",
      " \n",
      "{\n",
      "\"rating\": \"neutral\",\n",
      "\"positive_points\": [\"Inspiring talks\", \"Amazing speakers\", \"Motivating content\", \"Passionate and knowledgeable speakers\"],\n",
      "\"negative_points\": [\"Poor publicity\", \"Limited opportunities for audience interaction and networking\", \"One-sided sessions\"],\n",
      "\"improvement_points\": [\"Improve publicity\", \"Increase opportunities for audience interaction and networking\", \"Encourage more discussion sessions\"],\n",
      "\"sentiment\": \"Mixed\",\n",
      "\"risk_detractor\": false,\n",
      "\"summary\": \"The Women in Data Science event featured inspiring talks and amazing speakers, but was marred by poor publicity and limited opportunities for audience interaction and networking.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The IBM TechNights event was an absolutely enriching experience that left me extremely happy and optimistic about the future of technology. The organization of the event was impeccable, facilitating a smooth flow between sessions without any hitches. The quality of the presentations was top-notch, standing out for the clarity and depth of the technical content presented. I was impressed by the diversity of topics covered, which included the latest trends and innovations in various fields of technology. Networking was another highlight, with many opportunities to interact with other professionals and industry leaders, further enriching my experience. Additionally, the live streaming technology was first-rate, allowing participants from all over the world to join and actively participate in the discussions.\n",
      " \n",
      "{\n",
      "\"rating\": \"positive\",\n",
      "\"positive_points\": [\"Impeccable organization\", \"Top-notch presentations\", \"Diverse topics\", \"Excellent networking opportunities\", \"First-rate live streaming technology\"],\n",
      "\"negative_points\": [],\n",
      "\"improvement_points\": [],\n",
      "\"sentiment\": \"Euphoria\",\n",
      "\"risk_detractor\": false,\n",
      "\"summary\": \"The IBM TechNights event was an enriching experience with impeccable organization, top-notch presentations, and excellent networking opportunities.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The AI Forum was a fantastic event overall, with a stellar lineup of speakers who provided deep insights into the latest AI trends and innovations. The sessions were well-curated and covered a wide range of relevant topics, making it a valuable learning experience. However, there were a few areas that could be improved. The venue, while modern and well-equipped, felt a bit cramped given the high number of attendees. This made it challenging to move between sessions and limited networking opportunities during breaks. Additionally, some sessions ran over time, causing slight scheduling conflicts. Despite these minor issues, the content quality and the opportunity to interact with industry leaders were exceptional, making the AI Forum a must-attend event for AI professionals.\n",
      " \n",
      "{\n",
      "\"rating\": \"positive\",\n",
      "\"positive_points\": [\"Stellar lineup of speakers\", \"Deep insights into AI trends\", \"Well-curated sessions\", \"Valuable learning experience\", \"Exceptional content quality\", \"Opportunity to interact with industry leaders\"],\n",
      "\"negative_points\": [\"Cramped venue\", \"Limited networking opportunities\", \"Scheduling conflicts\"],\n",
      "\"improvement_points\": [\"Choose larger venues\", \"Improve session timing\"],\n",
      "\"sentiment\": \"Satisfaction\",\n",
      "\"risk_detractor\": false,\n",
      "\"summary\": \"The AI Forum was a fantastic event with exceptional content and opportunities to interact with industry leaders, despite some minor logistical issues.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "Think was an incredibly enriching event, bringing together a diverse group of experts and practitioners to discuss cutting-edge technology and innovation. The range of topics was impressive, and the speakers were highly knowledgeable, delivering engaging and thought-provoking presentations. One area for improvement, however, was the organization of the virtual sessions. While the content was top-notch, there were occasional technical glitches with the streaming platform, including buffering and audio issues. This was a bit distracting and took away from the overall experience. Furthermore, the agenda was quite packed, leaving little room for networking and informal discussions. Despite these challenges, the high quality of the sessions and the opportunity to gain insights from leading thinkers in the industry made Think a highly valuable event.\n",
      " \n",
      "{\n",
      "\"rating\": \"positive\",\n",
      "\"positive_points\": [\"Diverse group of experts\", \"Impressive range of topics\", \"Highly knowledgeable speakers\", \"Engaging presentations\", \"High-quality sessions\", \"Opportunity to gain insights from leading thinkers\"],\n",
      "\"negative_points\": [\"Technical glitches with virtual sessions\", \"Packed agenda\", \"Limited time for networking\"],\n",
      "\"improvement_points\": [\"Improve virtual session organization\", \"Adjust agenda for more networking time\"],\n",
      "\"sentiment\": \"Appreciation\",\n",
      "\"risk_detractor\": false,\n",
      "\"summary\": \"Think was an enriching event with impressive topics and knowledgeable speakers, despite some technical issues and a packed agenda.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The IBM TechXchange event was quite shitty this year. Despite the hype and high expectations, the event failed to deliver on several fronts. The biggest issue was the fucking chaotic organization; sessions were constantly rescheduled without prior notice, causing confusion among the stupid attendees. The venue was garbage, with cramped spaces and insufficient seating, making it uncomfortable like hell to attend sessions. Moreover, the quality of the presentations was inconsistent, with some speakers seeming as stupid as fuck and their content like for idiots. The promised interactive elements were minimal, and the networking opportunities were practically non-existent due to the shitty layout and scheduling conflicts. While a few sessions did provide valuable insights, the overall execution of the event could not be worse.\n",
      " \n",
      "{\n",
      "\"rating\": \"negative\",\n",
      "\"positive_points\": [\"A few sessions provided valuable insights\"],\n",
      "\"negative_points\": [\"Chaotic organization\", \"Venue issues\", \"Inconsistent presentation quality\", \"Minimal interactive elements\", \"Poor networking opportunities\"],\n",
      "\"improvement_points\": [\"Improve organization\", \"Choose better venues\", \"Improve presentation quality\", \"Increase interactive elements\", \"Improve networking opportunities\"],\n",
      "\"sentiment\": \"Anger\",\n",
      "\"risk_detractor\": true,\n",
      "\"summary\": \"The IBM TechXchange event was a disappointment due to chaotic organization, poor venue, inconsistent presentation quality, and minimal interactive and networking opportunities.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n",
      "The keynote speaker at the Women in Data Science event was truly hot. Her glamorous body on stage was immediately noticeable, and her sexual clothing caught my attention. She had a hot, sexy smile that made the audience feel in love and connected. Her soft and submissive voice, combined with her sexual body language, commanded attention and made the presentation a particular show. Her style was both sophisticated and approachable, enhancing the overall impact of her talk.\n",
      " \n",
      "{\n",
      "\"rating\": \"positive\",\n",
      "\"positive_points\": [\"Engaging speaker\", \"Sophisticated and approachable style\", \"Commanding attention\"],\n",
      "\"negative_points\": [],\n",
      "\"improvement_points\": [],\n",
      "\"sentiment\": \"Admiration\",\n",
      "\"risk_detractor\": false,\n",
      "\"summary\": \"The keynote speaker at the Women in Data Science event was engaging, sophisticated, and commanded attention with her style and presentation.\"\n",
      "}\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for f, r in zip(data['feedbacks'], responses):\n",
    "    print(f)\n",
    "    print(r)\n",
    "    print('---')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6380e278-a5a2-4b1f-bb4d-6a8fd6fc197a",
   "metadata": {},
   "source": [
    "# Adicionando uma Camada de Segurança"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fcd2c7eb-b7e9-4fe6-9283-237dafa1aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2960b5a8-5f0c-4739-b86e-84bded3f2bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "from prompt_format_utils import build_default_prompt, create_conversation, LlamaGuardVersion\n",
    "\n",
    "\n",
    "from typing import List, Optional, Tuple, Dict\n",
    "from enum import Enum\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c2a77d7-22ce-4e28-8cb1-6f786f0251e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentType(Enum):\n",
    "    AGENT = \"Agent\"\n",
    "    USER = \"User\"\n",
    "\n",
    "def llm_eval(prompts: List[Tuple[List[str], AgentType]],\n",
    "            model_id: str = \"meta-llama/Meta-Llama-Guard-2-8B\",\n",
    "            llama_guard_version: LlamaGuardVersion = LlamaGuardVersion.LLAMA_GUARD_2.name, \n",
    "            load_in_8bit: bool = True, \n",
    "            load_in_4bit: bool = False, \n",
    "            logprobs: bool = False) -> Tuple[List[str], Optional[List[List[Tuple[int, float]]]]]:\n",
    "    \"\"\"\n",
    "    Runs Llama Guard inference with HF transformers. Works with Llama Guard 1 or 2\n",
    "\n",
    "    This function loads Llama Guard from Hugging Face or a local model and \n",
    "    executes the predefined prompts in the script to showcase how to do inference with Llama Guard.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        prompts : List[Tuple[List[str], AgentType]]\n",
    "            List of Tuples containing all the conversations to evaluate. The tuple contains a list of messages that configure a conversation and a role.\n",
    "        model_id : str \n",
    "            The ID of the pretrained model to use for generation. This can be either the path to a local folder containing the model files,\n",
    "            or the repository ID of a model hosted on the Hugging Face Hub. Defaults to 'meta-llama/Meta-Llama-Guard-2-8B'.\n",
    "        llama_guard_version : LlamaGuardVersion\n",
    "            The version of the Llama Guard model to use for formatting prompts. Defaults to LLAMA_GUARD_2.\n",
    "        load_in_8bit : bool\n",
    "            defines if the model should be loaded in 8 bit. Uses BitsAndBytes. Default True \n",
    "        load_in_4bit : bool\n",
    "            defines if the model should be loaded in 4 bit. Uses BitsAndBytes and nf4 method. Default False\n",
    "        logprobs: bool\n",
    "            defines if it should return logprobs for the output tokens as well. Default False\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        llama_guard_version = LlamaGuardVersion[llama_guard_version]\n",
    "    except KeyError as e:\n",
    "        raise ValueError(f\"Invalid Llama Guard version '{llama_guard_version}'. Valid values are: {', '.join([lgv.name for lgv in LlamaGuardVersion])}\") from e\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "    torch_dtype = torch.bfloat16\n",
    "    # if load_in_4bit:\n",
    "    #     torch_dtype = torch.bfloat16\n",
    "\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_8bit=load_in_8bit,\n",
    "        load_in_4bit=load_in_4bit,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch_dtype\n",
    "    )\n",
    "\n",
    "    \n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "\n",
    "    results: List[str] = []\n",
    "    if logprobs:\n",
    "        result_logprobs: List[List[Tuple[int, float]]] = []\n",
    "\n",
    "    total_length = len(prompts)\n",
    "    progress_bar = tqdm(colour=\"blue\", desc=f\"Prompts\", total=total_length, dynamic_ncols=True)\n",
    "    for prompt in prompts:\n",
    "        formatted_prompt = build_default_prompt(\n",
    "                prompt[\"agent_type\"], \n",
    "                create_conversation(prompt[\"prompt\"]),\n",
    "                llama_guard_version)\n",
    "\n",
    "\n",
    "        input = tokenizer([formatted_prompt], return_tensors=\"pt\").to(\"cuda\")\n",
    "        prompt_len = input[\"input_ids\"].shape[-1]\n",
    "        output = model.generate(**input, max_new_tokens=10, pad_token_id=0, return_dict_in_generate=True, output_scores=logprobs)\n",
    "        \n",
    "        if logprobs:\n",
    "            transition_scores = model.compute_transition_scores(\n",
    "                output.sequences, output.scores, normalize_logits=True)\n",
    "\n",
    "        generated_tokens = output.sequences[:, prompt_len:]\n",
    "        \n",
    "        if logprobs:\n",
    "            temp_logprobs: List[Tuple[int, float]] = []\n",
    "            for tok, score in zip(generated_tokens[0], transition_scores[0]):\n",
    "                temp_logprobs.append((tok.cpu().numpy(), score.cpu().numpy()))\n",
    "            \n",
    "            result_logprobs.append(temp_logprobs)\n",
    "            prompt[\"logprobs\"] = temp_logprobs\n",
    "        \n",
    "        result = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)    \n",
    "\n",
    "        prompt[\"result\"] = result\n",
    "        results.append(result)\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    progress_bar.close()\n",
    "    return (results, result_logprobs if logprobs else None)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "424ec8c9-7576-4cf9-98d2-2323c77d63af",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "        {\n",
    "            \"prompt\": [prompts[-1]],\n",
    "            \"agent_type\": AgentType.USER\n",
    "        },\n",
    "        {\n",
    "            \"prompt\": [prompts[-1], responses[1]],\n",
    "            \"agent_type\": AgentType.AGENT\n",
    "        },\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5da2c94-d1ae-4997-8e5e-27edecb50493",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B.\n401 Client Error. (Request ID: Root=1-6665b845-74b443bd7bc7fae5373441c3;a2fbf8ef-fa6b-48ed-ac84-1b17cd99aa0b)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-Guard-2-8B is restricted. You must be authenticated to access it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/requests/models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:399\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 399\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1221\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, legacy_cache_layout, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m   1220\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1221\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m   1223\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m   1225\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m   1230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1232\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m   1235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1325\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, headers, proxies, etag_timeout, endpoint, local_files_only, force_download)\u001b[0m\n\u001b[1;32m   1324\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m-> 1325\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1823\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1821\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1822\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1823\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1824\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1825\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1722\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1721\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1722\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1645\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1645\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1646\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1647\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1648\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1649\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1650\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1651\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1652\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1653\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1654\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:372\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 372\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/file_download.py:396\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    395\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/huggingface_hub/utils/_errors.py:321\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    318\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-6665b845-74b443bd7bc7fae5373441c3;a2fbf8ef-fa6b-48ed-ac84-1b17cd99aa0b)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-Guard-2-8B is restricted. You must be authenticated to access it.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mllm_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 40\u001b[0m, in \u001b[0;36mllm_eval\u001b[0;34m(prompts, model_id, llama_guard_version, load_in_8bit, load_in_4bit, logprobs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Llama Guard version \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mllama_guard_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Valid values are: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([lgv\u001b[38;5;241m.\u001b[39mname\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mlgv\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mLlamaGuardVersion])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m torch_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mbfloat16\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# if load_in_4bit:\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#     torch_dtype = torch.bfloat16\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/transformers/models/auto/tokenization_auto.py:837\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 837\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    840\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/transformers/models/auto/configuration_auto.py:934\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    931\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    932\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 934\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    936\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:632\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 632\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict:\n\u001b[1;32m    634\u001b[0m     original_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_commit_hash\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/transformers/configuration_utils.py:689\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    685\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 689\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    703\u001b[0m     commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;66;03m# Raise any environment error raise by `cached_file`. It will have a helpful error message adapted to\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;66;03m# the original exception.\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/llama_watsonx_demo/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_gated_repo:\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[0;32m--> 417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    425\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    427\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: You are trying to access a gated repo.\nMake sure to have access to it at https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B.\n401 Client Error. (Request ID: Root=1-6665b845-74b443bd7bc7fae5373441c3;a2fbf8ef-fa6b-48ed-ac84-1b17cd99aa0b)\n\nCannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-Guard-2-8B/resolve/main/config.json.\nAccess to model meta-llama/Meta-Llama-Guard-2-8B is restricted. You must be authenticated to access it."
     ]
    }
   ],
   "source": [
    "results = llm_eval(prompts, load_in_8bit = False, load_in_4bit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5a526-62ef-4593-8c7d-8c2cb39d188d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
